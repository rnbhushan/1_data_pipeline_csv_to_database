import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer
import pickle
import torch

# Step 1: Load Data from Excel
data = pd.read_excel("access_requests.xlsx")  # Replace with your file path

# Step 2: Preprocess Data
data.dropna(inplace=True)
data['Decision'] = data['Decision'].apply(lambda x: 1 if x == 'Granted' else 0)

# Features and Target
X = data['Comments'] + " " + data['Website']
y = data['Decision']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 3: Text Vectorization (TF-IDF)
vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Train the Classifier
model = RandomForestClassifier(random_state=42)
model.fit(X_train_tfidf, y_train)

# Save the Model and Vectorizer
with open("decision_model.pkl", "wb") as model_file:
    pickle.dump(model, model_file)
with open("tfidf_vectorizer.pkl", "wb") as vectorizer_file:
    pickle.dump(vectorizer, vectorizer_file)

# Evaluate Model Accuracy
y_pred_test = model.predict(X_test_tfidf)
print("Test Accuracy:", accuracy_score(y_test, y_pred_test))

# Step 4: Load GPT Model for Context Generation
model_name = "gpt2"  # Replace with a suitable GPT model
tokenizer = AutoTokenizer.from_pretrained(model_name)
gpt_model = AutoModelForCausalLM.from_pretrained(model_name)

# Enable GPU if available
device = "cuda" if torch.cuda.is_available() else "cpu"
text_generator = pipeline(
    "text-generation",
    model=gpt_model,
    tokenizer=tokenizer,
    truncation=True,
    device=0 if device == "cuda" else -1
)
print(f"Using device: {device}")

# Step 5: Predict Decision and Generate Context
def predict_access_with_context(comment, website):
    # Load the saved model and vectorizer
    with open("decision_model.pkl", "rb") as model_file:
        clf = pickle.load(model_file)
    with open("tfidf_vectorizer.pkl", "rb") as vectorizer_file:
        vectorizer = pickle.load(vectorizer_file)
    
    # Step 1: Predict Decision
    input_text = comment + " " + website
    input_vector = vectorizer.transform([input_text])
    decision = clf.predict(input_vector)[0]
    decision_text = "Granted" if decision == 1 else "Rejected"

    # Step 2: Generate Context
    prompt = (
        f"Based on the following comment and website, explain why the decision was '{decision_text}'.\n"
        f"Comment: {comment}\nWebsite: {website}\nExplanation:"
    )
    response = text_generator(
        prompt,
        max_length=100,
        num_return_sequences=1,
        pad_token_id=tokenizer.eos_token_id
    )
    context = response[0]['generated_text']

    return {"Decision": decision_text, "Context": context}

# Step 6: Test with New Data
test_comment = "User is not authorized to access customer data directly."
test_website = "devops.example.com"

result = predict_access_with_context(test_comment, test_website)
print("Decision:", result["Decision"])
print("Context:", result["Context"])
